{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf945426-1c02-4696-a4ad-3856f7eee66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7b3724-521f-4a11-ae61-6b23c1760101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the environment and extract the number of actions.\n",
    "ENV_NAME = 'JSSEnv:jss-v1'\n",
    "env = gym.make(ENV_NAME)\n",
    "np.random.seed(123)\n",
    "env.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2abc5c4-482e-465a-96c2-f2fe4a8aa135",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb566a28-754b-4b91-bdfd-e904b5b73446",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290af4d7-211f-4714-9e8f-bd7852f5f688",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70a5c845-c2d1-4e8d-afbe-efb46bcd5960",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_points(k):\n",
    "    x = np.random.rand(k, 50)\n",
    "    y = np.random.choice([0, 1], size=k, p=[0.5, 0.5]).reshape([-1, 1])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e01f5c70-862b-4b88-aa46-a3d8a0751b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss 1.610030811967183\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Epoch 1000: Loss 0.984637979867634\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Epoch 2000: Loss 1.530308496020515\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Epoch 3000: Loss 0.789037479334159\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Epoch 4000: Loss 1.5148659210677553\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Epoch 5000: Loss 0.9242187537106432\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Epoch 6000: Loss 1.0267064403562376\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Epoch 7000: Loss 0.8528557403258459\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Epoch 8000: Loss 1.0075481942430713\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Epoch 9000: Loss 1.2613949878820534\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "15.998469114303589\n",
      "Epoch 0: Loss 1.0427040079754037\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Epoch 1000: Loss 0.937232062971488\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Epoch 2000: Loss 1.1835404109856156\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Epoch 3000: Loss 1.0152892987720314\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Epoch 4000: Loss 0.7000608207367799\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Epoch 5000: Loss 0.9011506265584519\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Epoch 6000: Loss 0.8662780590051982\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Epoch 7000: Loss 1.0007899099009279\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Epoch 8000: Loss 1.0508301522285795\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Epoch 9000: Loss 1.3483174258171065\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "17.649560689926147\n"
     ]
    }
   ],
   "source": [
    "class MAML:\n",
    "    def __init__(self):\n",
    "        # initialize number of tasks i.e number of tasks we need in each batch of tasks\n",
    "        self.num_tasks = 10\n",
    "        # number of samples i.e number of shots -number of data points (k) we need to have in each task\n",
    "        self.num_samples = 10\n",
    "        # number of epochs i.e training iterations\n",
    "        self.epochs = 10000\n",
    "        # hyperparameter for the inner loop (inner gradient update)\n",
    "        self.alpha = 0.0001\n",
    "        # hyperparameter for the outer loop (outer gradient update) i.e meta optimization\n",
    "        self.beta = 0.0001\n",
    "        # randomly initialize our model parameter theta\n",
    "        self.theta = np.random.normal(size=50).reshape(50, 1)\n",
    "\n",
    "    def sigmoid(self, a):\n",
    "        return 1.0 / (1 + np.exp(-a))\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        # for the number of epochs,\n",
    "        for e in range(self.epochs):\n",
    "\n",
    "            self.theta_ = []\n",
    "\n",
    "            # for task i in batch of tasks\n",
    "            for i in range(self.num_tasks):\n",
    "\n",
    "                # sample k data points and prepare our train set\n",
    "                XTrain, YTrain = sample_points(self.num_samples)\n",
    "\n",
    "                a = np.matmul(XTrain, self.theta)\n",
    "\n",
    "                YHat = self.sigmoid(a)\n",
    "\n",
    "                # since we are performing classification, we use cross entropy loss as our loss function\n",
    "                loss = (\n",
    "                    (\n",
    "                        np.matmul(-YTrain.T, np.log(YHat))\n",
    "                        - np.matmul((1 - YTrain.T), np.log(1 - YHat))\n",
    "                    )\n",
    "                    / self.num_samples\n",
    "                )[0][0]\n",
    "\n",
    "                # minimize the loss by calculating gradients\n",
    "                gradient = np.matmul(XTrain.T, (YHat - YTrain)) / self.num_samples\n",
    "\n",
    "                # update the gradients and find the optimal parameter theta' for each of tasks\n",
    "                self.theta_.append(self.theta - self.alpha * gradient)\n",
    "\n",
    "            # initialize meta gradients\n",
    "            meta_gradient = np.zeros(self.theta.shape)\n",
    "\n",
    "            for i in range(self.num_tasks):\n",
    "\n",
    "                # sample k data points and prepare our test set for meta training\n",
    "                XTest, YTest = sample_points(10)\n",
    "\n",
    "                # predict the value of y\n",
    "                a = np.matmul(XTest, self.theta_[i])\n",
    "\n",
    "                YPred = self.sigmoid(a)\n",
    "\n",
    "                # compute meta gradients\n",
    "                meta_gradient += np.matmul(XTest.T, (YPred - YTest)) / self.num_samples\n",
    "\n",
    "            # update our randomly initialized model parameter theta with the meta gradients\n",
    "            self.theta = self.theta - self.beta * meta_gradient / self.num_tasks\n",
    "\n",
    "            if e % 1000 == 0:\n",
    "                print(\"Epoch {}: Loss {}\\n\".format(e, loss))\n",
    "                print(\"---------------------------------\\n\")\n",
    "\n",
    "\n",
    "x = MAML()\n",
    "start = time.time()\n",
    "x.train()\n",
    "print(time.time() - start)\n",
    "new_start = time.time()\n",
    "x.train()\n",
    "print(time.time() - new_start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a07a0be-4133-487b-8992-82ab681e881f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

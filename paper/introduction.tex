\chapter{Introduction}\label{sec:intro}

\setcounter{page}{1}

The cloud is everywhere. All companies in the tech big 5, i.e. Facebook,
Apple, Amazon, Netflix and Google, use the cloud extensively and offer many
cloud services to their users. Movies are not bought anymore, but rather
streamed. New MacBooks do not come with much storage. Instead, each purchase
includes some storage in Apple's cloud. How are the movies and pictures stored
in the cloud? What even is the cloud? The cloud is a network of many
interconnected computers, the nodes in the network, providing resources.
Oftentimes these nodes are abstracted as just resources. The utilisation of
these resources need to be managed, which is done by schedulers. Efficient
schedulers are essential, because they directly influence the cloud platform by
having a high resource utilization rate and end-users by having a good quality
of service. This thesis investigates methods for improving the robustness of
schedulers.


\section{Background}
\subsection{The Cloud}\label{sec:cloud}

The cloud is a popular term used for (a network of) data centres containing
many computers that provide resources, for example storage and computational
power. These computers communicate via standard network protocols locally.
Data centres thus contain many computers that provide computational resources.
The four significant advantages of using data centres for large computational
tasks are the following: 1) Distributed. Data centres are the ideal
environment for running distributed software, because the structure of data
centres offers much distributed scalability; 2) Robustness. When a component
breaks, the scheduler could migrate the task to other available resources, and
the broken component can be replaced while the application is still running;
3) Configurable. The resources can be selected based on computation
requirements of the task. Providing many different configurations improve the
utilisation rate and efficiency of cloud platforms; 4) Scalability. Data centres
offer virtualised resources and are thus easier to scale. Availability of
resources can easily be scaled.

An additional benefit of the cloud is how companies pay for the resources,
i.e. pay-as-you-go. Pay-as-you-go means that companies never pay for idle
resources and can easily scale up to use more resources when needed. By
building and sharing large data centres, companies can effectively achieve the
economies of scale principle for needed resources. Economy of scales reduces
the cost of the resources, but also the maintenance costs.


\subsection{Job Scheduling}\label{sec:scheduling}

Imagine cloud systems as described in Section \ref{sec:cloud}. These systems
have many tasks, or as in this thesis called jobs, that need to be executed to
scheduler. These jobs vary a lot in duration time and required resources. To
illustrate, given that the cloud environment provides a back-end for a
website. A job could be one of the following: Serving the right HTML page to a
visiting user, compressing user-uploaded images, spam filtering, detecting
anomalies in user logins or many other types of jobs that need to be executed
to provide a functioning website. The scheduler allocates jobs over
many resources. Optimally allocating the jobs is important for cloud
environments because efficiently using resources could improve the resource
utilisation rate and the quality of service.

What is scheduling efficiency and how can schedulers be efficient? There are
many metrics on which optimization can be done to improve the efficiency of a
scheduler. For example, minimizing job slowdown time, minimizing average
completion time, maximizing throughput (jobs per time unit) or minimizing
total completion time (the makespan). Schedulers are created to be optimised
on one or more of these aspects, varying the importance. Unfortunately, the
optimization of schedulers is complex. It is a well-known problem in computer
science because of its NP-hardness. The next paragraph explains what it means
to be a NP-hard problem and why job scheduling is NP-hard.


\subsubsection{NP-Hard}

NP-hardness is a term used in the P versus NP problem. This problem is one of
the seven Millennium Prize Problems \cite{carlson2006} and still unsolved. The
P versus NP problem is about computational complexity, an approach to
categorizing problems based on `how hard' they are. Computational problems
have two complexity aspects: the complexity to solve the problem and the
complexity to verify if the solution to the problem is correct. The question
is, if the solution to a given problem can be verified quickly (in polynomial
time), is there an algorithm that can find the solution quickly? Problems that
can be \emph{solved} in polynomial time are in the P class. Problems that can
be \emph{verified} in polynomial time are in the NP (nondeterministic
polynomial time) class. If these classes entirely overlap, i.e. every problem in
P is also in NP, and every problem in NP is also in P, then P equals NP. Many
computer scientists believe this is not the case for all problems
\cite{rosenberger2012}. Believed is that there are problems that can be
verified quickly but not solved quickly, called NP-hard problems. A
well-known NP-hard problem is the Sudoku puzzle, especially larger ones
\cite{yato2003}.

Job scheduling is a generalised version of the travelling salesperson problem.
The problem is as follows: ``Given a list of cities and the distances between
each pair of cities, what is the shortest possible route that visits each city
exactly once and returns to the origin city?'' \cite{flood1956}. In this
problem, the cities are the resources, and the salesman is the job.

Job scheduling is NP-hard because it can be derived from the Graph Coloring
Problem, as done in \citeA{karp1972}. The graph colouring problem is an NP-hard
problem itself.


\subsection{Heuristics-based Scheduling Methods}\label{sec:situ}

Many cloud job schedulers that are still used today are explicitly developed
for the system it manages, based on simple heuristics and fine-tuned by trial
and error. Tuning job schedulers is a tedious task. Repeating work of adjusting
parameters and testing is very time-consuming. Current cloud schedulers are
developed for ease of understanding. The schedulers generalize,
i.e. they perform the same job regardless of whether the workload is heavy or
light \cite{mao2019}. Three classic (non-\ai) algorithms are explained below
to provide an idea of the simplicity of the non-\ai schedulers.

\begin{enumerate}
\item First in, first out (FIFO): This algorithm treats the awaiting jobs like
    a queue. All available resources are filled, and when a resource is
        available it is assigned to the task first in queue.
\item Shortest Job First (SJF): This algorithm sorts awaiting jobs based on
    increasing order of an estimation of the completion time. It works the
        same as FIFO for workload: when a resource is free, it is assigned a
        new job from the queue. It can be described as a priority queue.
\end{enumerate}

The above-explained algorithms are highly intuitive resource managers and not
fine-tuned for different workloads. Due to the lack of flexibility of these
non-\ai algorithms, there are also situations in which their scheduling
efficiency and precision will have deviation. More specifically, FIFO possibly
leads to multiple jobs with a long duration time, blocking all other jobs till
they finish. The disadvantage of SJF is that it can cause starvation, meaning
that short jobs are constantly added and will never be executed.


\subsection{Machine Learning Based Scheduling Methods}

Currently, schedulers are not capable of handling differences in workload and
have other shortcomings. There is a need for schedulers capable of handling
increasingly complex large-scale systems. Due to the shortcomings of current
non-\ai implementations, research is done in using \ml techniques to learn
efficient scheduling. This research is discussed in Section
\ref{sec:state-of-the-art}. Machine learning tends to overfit, and that it
does not generalize. It might not be flexible. Overfitting is also the case
with \rlbased schedulers. Schedulers can show undefined behaviour when
resources are added or removed. Thus, when a change in environment occurs,
the \rlbased scheduler gets retrained to work in the new environment. If
retraining has to be done for every environment change, it would spend more
time retraining than scheduling.


\section{Motivation}

Retraining is not ideal and should be prevented as much as possible. The
disadvantages of it are that retraining\dots

\begin{itemize}[noitemsep]
    \item[\dots] takes time, in which a sub-optimally working scheduler is
        still scheduling;
    \item[\dots] costs computational resources itself, which can not be used
        for performing other jobs;
    \item[\dots] costs money and contributes to global warming. Carbon
        emission of large \ml models is a real issue which is currently
        researched on \cite{patterson2021};
    \item[\dots] means that the scheduler is not robust enough. Improving the
        robustness of schedulers can improve the quality of service for an
        end-user, reduce the cost for a company and impact the environment.
\end{itemize}


\section{Research Questions}

The goal of this research is to integrate robustness into current
state-of-the-art \ml based job schedulers. This leads to the following
research question:
\begin{quote}
How to select a method for reducing the retraining time of reinforcement learning
    based resource schedulers in cloud environments?
\end{quote}
This will be answered by the following sub-questions:
\begin{enumerate}[noitemsep]
    \item How can we effectively assess and compare \rlbased methods in job
        scheduling?
    \item What are the indicators to assess the robustness of \rlbased schedulers?
    \item What are the state-of-the-art approaches for reducing retraining time?
\end{enumerate}
The goal of this research is to provide indicators for selecting methods that
reduce retraining time. To find the indicators, it is first needed to assess
\rlbased schedulers. More robust (also called flexible) \rlbased schedulers
can work with environmental changes and thus need less retraining time.
Even though the training time does not change, requiring less retraining still
reduces the overall retraining time. It is also required to know what
state-of-the-art approaches are for reducing retraining time. Based on
aspects of state-of-the-art approaches, criteria can be formed to select
approaches for reducing retraining time.

There are two challenges of the research questions. The first challenge is how
a method for reducing the retraining time can be selected if there is are no
indicators to assess robustness of a \rlbased scheduler. Comparing is not
possible without indicators. The second challenge is to create a testbed that
can test every arbitrary \rl algorithm on a \jss problem, using the same data.


\section{Contributions}

This thesis seeks to contribute the following to the field of \rlbased
schedulers:

\begin{enumerate}[noitemsep]
    \item This thesis discusses the methods for assessing the performance
        of \rl models, explain the difference and why some methods might be
        better. This contributes to the field by helping others select a
        method of assessing the performance of a \rl model.
    \item This thesis discusses approaches to assessing the robustness of
        \rl models. This contributes to the field by introducing the
        importance of robustness and explaining how a method for adding in
        robustness can be selected.
    \item This thesis will contribute the field by listing the
        state-of-the-art approaches for reducing retraining time. This
        contributes to the field by helping others to select a method for
        reducing retraining time.
    \item This thesis will contribute to an approach for selecting
        reinforcement learning-based schedulers on the following indicators:
        the overall performance of the model, the robustness of the model and
        the training time.
\end{enumerate}


In this thesis related work will first be discussed in Section
\ref{sec:state-of-the-art}. Thereafter the methodology and implementation of
the experiments is discussed in Section \ref{sec:method}. Thereafter the
experiments and their results are described in Section
\ref{sec:experiments}. After this the results will be discussed in Section
\ref{sec:discussion} and a conclusion will be drawn in Section
\ref{sec:conclusion}. This thesis will end with suggestions for future work in
Section \ref{sec:future-work}.

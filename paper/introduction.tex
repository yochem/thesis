\chapter{Introduction}\label{sec:intro}

The cloud is everywhere. All companies in the tech big 5, i.e. Facebook,
Apple, Amazon, Netflix and Google, use the cloud extensively and offer many cloud
services to their users. Movies are not bought anymore, but streamed. New
MacBooks do not come with much storage, instead buyers get some storage in the
Apple cloud. But how are the movies and pictures stored in the cloud? What
even is the cloud? In this thesis it is shown that the cloud is a network of
many computers. These computers need to be managed, which is done by
schedulers. Efficient schedulers is very useful, because this means that using
cloud services becomes more efficient. In this thesis we look at how methods
for improving this efficiency can be selected.

In this chapter the many aspects of resource schedulers in cloud environments
are discussed. Firstly, in Section \ref{sec:cloud} cloud environments are
discussed. Secondly some theoretical background about the problem of job
scheduling and its NP-hardness is provided in Section \ref{sec:scheduling}.
Lastly, in the Section \ref{sec:situ} the scope of the presented thesis is
defined, the current situation is evaluated, the gap is identified and a
research question is stated.

\section{The Cloud}\label{sec:cloud}

The cloud is a popular term used for (a network of) data centers containing
many computers that provide resources, for example storage and computing
power. These computers communicate via standard network protocols locally.
Data centers thus contain many computers that provide computing resources. The
four major advantages of using data centers for large computing tasks are the
following: 1) Distributed. Data centers are the ideal environment for running
distributed software, because the nature of data centers is distributed
computing; 2) Robustness. When one computer breaks, the task can be sent to
another computer and the broken computer can be replaced while the application
is still running; 3) Configurable. The computer can be selected based on the
resource-need of the task. Providing many different configurations can make
sure that tasks fully utilize all the resources the computer provides; 4)
Scalability. Data centers are modular and thus easier to scale. New computers
can be added and connected to the network and directly be used.

An additional benefit of the cloud is how companies pay for the resources they
need. This way, companies never pay for idle resources and can easily scale up
to use more resources when needed. By building and sharing huge data centers,
companies can effectively achieve the economies of scale principle for needed
resources. This reduces the cost of the resources, but also the maintenance
costs. The reason cost is reduced because resources are bought in bulk and
maintenance costs are reduced because there are less maintainers needed.


\section{Current Situation and Improvements}\label{sec:situ}

In this section current traditional (non-AI) schedulers are reviewed and
improvements using \ai techniques like \rl are
evaluated. The problem with current \ai improvements of schedulers are
identified and the aim of this resource is stated. The scope of this thesis is
narrowed down to reducing retraining time of \rl based schedulers in cloud
environments. The choices made in defining the terms and scopes of this thesis
are listed in the following paragraph.

\subsection{Traditional Schedulers}

Current cloud resource managers are developed specifically for the system it
manages, based on simple heuristics and fine tuned by trial and error.
Creating the resource managers is a hard and tedious task. A common aspect of
the resource managers based on simple heuristics is the straightforwardness.
Current cloud schedulers are developed for ease of understanding. The
schedulers generalize, i.e. they perform the same job regardless of whether
the workload is heavy or light \cite{mao2019}. Three classic (non-\ai)
algorithms are explained below to provide an idea of the simplicity of the
non-\ai schedulers.

\begin{enumerate}
\item First in, first out (FIFO): This algorithm treats the awaiting jobs like
    a queue and lets later jobs wait until earlier jobs finish and resources
    are available for the next job.
\item Shortest Job First (SJF): This algorithm sorts awaiting jobs based on
    increasing order of completion time.
\item Tetris: ? \note{hier tetris}
\end{enumerate}

The above explained algorithms are highly intuitive resource managers and not
fine tuned for different workloads. Due to the lack in flexibility of these
non-\ai algorithms , there are also situations in which they will perform much
worse than other algorithms will do. For FIFO this leads to multiple jobs with
a long duration time, blocking all other jobs till finish. The disadvantage of
SJF is that it can cause starvation, meaning that short jobs are constantly
added and will never be executed.

Currently, schedulers are not capable of handling differences in workload and
have other shortcomings. There is a need for schedulers that are capable of
handling increasingly complex large-scale systems, although the systems are
currently already too complex for humans to fully understand and schedule. Due
to the shortcomings of current non-\ai implementations, previous research is
done on implementing these resource managers using \ai technology. Recent
research, e.g. \citeA{mao2019, mao2016, zhang2020}, has shown that
using deep reinforcement learning for resource management improves average job
completion time by at least 21\% \cite{mao2019}.

\subsection{The Problem}

In the previous section the problem with non-\ai schedulers is identified.
Thereafter, improvements using \rl are shown, but these \rl improvements also
have their shortcomings. One of these shortcomings is flexibility. A known
problem of \ml algorithms is overfitting on the training
environment and not being able to work with environmental changes. This is
also the case with \rl based schedulers. Schedulers can show undefined behavior
when resources are added or removed. Thus, when a change in resources is done,
the \rl based schedulers need to be retrained to work in the new environment.
Retraining is a common problem with \ml algorithms. Retraining
takes time, in which a sub-optimally working scheduler is still scheduling.
Retraining also costs computing resources itself. This costs money and
contributes to global warming. Carbon emission of large \ml
models is a real issue which is currently researched on, e.g.
\citeA{patterson2021}. Finding ways to reduce retraining time of \rl models in
cloud environments is important, because many schedulers can benefit from
using these techniques. This makes cloud environments more efficient which is
better for the company in terms of costs, efficiency and maintenance and
better for the environment. It also contributes to more robust \rl schedulers.
If \rl schedulers are more robust, more cloud companies will switch to using \rl
based schedulers in stead of the current non-\ai schedulers.

The goal of this research is to integrate robustness into current
state-of-the-art \ml based resource managers. This leads to the following
research question: How to select a method for reducing retraining time of
reinforcement learning based resource schedulers in cloud environments? This
will be answered by the following sub-questions:

\begin{enumerate}
    \item How can we effectively assess and compare \rl based methods in job
        scheduling?
    \item What are the indicators to assess robustness of \rl based schedulers?
    \item What are the state-of-the-art approaches for reducing retraining time?
\end{enumerate}

\note{state the research aims and/or research objectives}

The goal of this research is to provide a method for selecting methods that
reduce retraining time. By reducing retraining time the models become more
flexible and

\note{TODO: State the hypotheses}

Firstly the state-of-the-art \rl schedulers and state-of-the-art methods for
reducing retraining time for \rl algorithms are reviewed and explained. In the
following chapter, the methodology of selecting methods is described.
Thereafter the results of this research are shown. Lastly, a conclusion of the
results is formed and discussed.

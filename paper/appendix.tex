\appendix

\chapter{Euro-Argo Log Data Analysis}\label{app:dataset}

These are the bash commands used for the data analysis in Table
\ref{table:files}.\\

\noindent Number of rows:
\begin{verbatim}
$ sed 1d mts_june_10m.csv | wc -l
$ sed 1d mts_june_10m_rh.csv | wc -l
$ sed 1d mts_june_1m.csv | wc -l
$ sed 1d mts_june_1m_rh.csv | wc -l
\end{verbatim}


\noindent Number of unique request IDs:
\begin{verbatim}
$ sed 1d mts_june_10m.csv | cut -d',' -f 3 | sort -h | uniq | wc -l
$ sed 1d mts_june_10m_rh.csv | cut -d',' -f 4 | sort -h | uniq | wc -l
$ sed 1d mts_june_1m.csv | cut -d',' -f 3 | sort -h | uniq | wc -l
$ sed 1d mts_june_1m_rh.csv | cut -d',' -f 4 | sort -h | uniq | wc -l
\end{verbatim}

\noindent Percentage completed (and after this $(N_{1} / (N_{1} + N_{0}) \cdot 10$):
\begin{verbatim}
$ sed 1d mts_june_10m.csv | cut -d',' -f 5 | sort | uniq -c
$ sed 1d mts_june_10m_rh.csv | cut -d',' -f 7 | sort | uniq -c
$ sed 1d mts_june_1m.csv | cut -d',' -f 5 | sort | uniq -c
$ sed 1d mts_june_1m_rh.csv | cut -d',' -f 7 | sort | uniq -c
\end{verbatim}


\chapter{MRLCO Data Parameter analysis}\label{app:mrlco}

As described in Section \ref{sec:dag}, the second line of every data file
showed the command that generated it (wrapped to fit into document, on one
line in actual data files):

\begin{verbatim}
// ./daggen --dot -n 20 --ccr 0.5 --fat 0.8 --regular 0.5
--density 0.4 --mindata 5242880 --maxdata 52428800
\end{verbatim}

To see the counts of each value for each parameter, the following command was
used:

\begin{verbatim}
for i in $(seq 4 2 16); do
    gsed -sn 2p */** | cut -d' ' -f $i,$((i=i+1)) | sort | uniq -c
    echo
done
\end{verbatim}

This resulted in the following output:

\begin{verbatim}
4716 -n 20

1564 --ccr 0.3
1587 --ccr 0.4
1565 --ccr 0.5

1000 --fat 0.4
1000 --fat 0.5
 916 --fat 0.6
 900 --fat 0.7
 900 --fat 0.8

4716 --regular 0.5

 716 --density 0.4
1000 --density 0.5
1000 --density 0.6
1000 --density 0.7
1000 --density 0.8

4716 --mindata 5242880

4716 --maxdata 52428800
\end{verbatim}
